{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset xsum (/home/vv2116/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934)\n",
      "100%|██████████| 3/3 [00:00<00:00, 234.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import get_dataset_split_names\n",
    "xsum_dataset = load_dataset(\"xsum\")\n",
    "from model import ModelMultitaskBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "parser = argparse.ArgumentParser(prog='myprogram', description='Foo')\n",
    "parser.add_argument('--expert_hidden_size', type=int, default=1024)\n",
    "parser.add_argument('--tower_hidden_size', type=int, default=1024)\n",
    "parser.add_argument('--hidden_size', type=int, default=1024) # 768 / 1024\n",
    "parser.add_argument('--bottom_hidden_size', type=int, default=1024)\n",
    "parser.add_argument('--num_experts', type=int, default=6)\n",
    "parser.add_argument('--scoring_methods', type=str, default = [\"rouge_1\",\"rouge_l\"])\n",
    "parser.add_argument('--k', type=int, default=3)\n",
    "\n",
    "parser.add_argument('--max_len', type=int, default=512)\n",
    "parser.add_argument('--max_summ_len', type=int, default=64)\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "args.n_tasks = len(args.scoring_methods)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "args.device = device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ModelMultitaskBinary\n",
    "from training_utils import *\n",
    "# from transformers import RobertaTokenizer, RobertaTokenizerFast, RobertaModel,BertTokenizer, BertTokenizerFast, BertModel\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration,PegasusTokenizer\n",
    "\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "base_model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "\n",
    "model = ModelMultitaskBinary(base_model, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>rls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "      <td>The clean-up operation is continuing in parts ...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>[0.5945945978164673, 0.523809552192688, 0.6999...</td>\n",
       "      <td>[0.5945945978164673, 0.523809552192688, 0.6999...</td>\n",
       "      <td>[0.4324324429035187, 0.3333333432674408, 0.550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed in a sus...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>[0.800000011920929, 0.9375, 0.8666666746139526...</td>\n",
       "      <td>[0.800000011920929, 0.9375, 0.8666666746139526...</td>\n",
       "      <td>[0.800000011920929, 0.9375, 0.8666666746139526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "      <td>Lewis Hamilton beat Mercedes team-mate Nico Ro...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>[0.8823529481887817, 0.8823529481887817, 0.848...</td>\n",
       "      <td>[0.8823529481887817, 0.8823529481887817, 0.848...</td>\n",
       "      <td>[0.5882353186607361, 0.5882353186607361, 0.606...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "      <td>A former Lincolnshire Police officer has gone ...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>[0.39024388790130615, 0.4324324429035187, 0.38...</td>\n",
       "      <td>[0.39024388790130615, 0.4324324429035187, 0.38...</td>\n",
       "      <td>[0.3414634168148041, 0.37837839126586914, 0.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "      <td>Turkish police have ended a siege at a psychia...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>[0.4864864945411682, 0.5714285969734192, 0.565...</td>\n",
       "      <td>[0.4864864945411682, 0.5714285969734192, 0.565...</td>\n",
       "      <td>[0.37837839126586914, 0.523809552192688, 0.478...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  The full cost of damage in Newton Stewart, one...   \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Ferrari appeared in a position to challenge un...   \n",
       "3  John Edward Bates, formerly of Spalding, Linco...   \n",
       "4  Patients and staff were evacuated from Cerahpa...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  The clean-up operation is continuing in parts ...   \n",
       "1  Two tourist buses have been destroyed in a sus...   \n",
       "2  Lewis Hamilton beat Mercedes team-mate Nico Ro...   \n",
       "3  A former Lincolnshire Police officer has gone ...   \n",
       "4  Turkish police have ended a siege at a psychia...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  Clean-up operations are continuing across the ...   \n",
       "1  Two tourist buses have been destroyed by fire ...   \n",
       "2  Lewis Hamilton stormed to pole position at the...   \n",
       "3  A former Lincolnshire Police officer carried o...   \n",
       "4  An armed man who locked himself into a room at...   \n",
       "\n",
       "                                                  r1  \\\n",
       "0  [0.5945945978164673, 0.523809552192688, 0.6999...   \n",
       "1  [0.800000011920929, 0.9375, 0.8666666746139526...   \n",
       "2  [0.8823529481887817, 0.8823529481887817, 0.848...   \n",
       "3  [0.39024388790130615, 0.4324324429035187, 0.38...   \n",
       "4  [0.4864864945411682, 0.5714285969734192, 0.565...   \n",
       "\n",
       "                                                  r2  \\\n",
       "0  [0.5945945978164673, 0.523809552192688, 0.6999...   \n",
       "1  [0.800000011920929, 0.9375, 0.8666666746139526...   \n",
       "2  [0.8823529481887817, 0.8823529481887817, 0.848...   \n",
       "3  [0.39024388790130615, 0.4324324429035187, 0.38...   \n",
       "4  [0.4864864945411682, 0.5714285969734192, 0.565...   \n",
       "\n",
       "                                                 rls  \n",
       "0  [0.4324324429035187, 0.3333333432674408, 0.550...  \n",
       "1  [0.800000011920929, 0.9375, 0.8666666746139526...  \n",
       "2  [0.5882353186607361, 0.5882353186607361, 0.606...  \n",
       "3  [0.3414634168148041, 0.37837839126586914, 0.33...  \n",
       "4  [0.37837839126586914, 0.523809552192688, 0.478...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"candidate_scores_samples.csv\")\n",
    "df[\"r1\"] = df[\"r1\"].apply(lambda arr : [float(val) for val in arr[2:-2].split(',')])\n",
    "df[\"r2\"] = df[\"r2\"].apply(lambda arr : [float(val) for val in arr[2:-2].split(',')])\n",
    "df[\"rls\"] = df[\"rls\"].apply(lambda arr : [float(val) for val in arr[2:-2].split(',')])\n",
    "# df[\"rls\"][1][0]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "dataset = MultitaskRerankingDatasetTrain(\"train\", tokenizer, df[df.columns[0]].tolist(), df[df.columns[1]].tolist(), df[df.columns[2]].tolist(),df[\"rls\"].tolist(), args.max_len,args.max_summ_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, default_data_collator\n",
    "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def nested_detach(tensors):\n",
    "        if isinstance(tensors, (list, tuple)):\n",
    "            return type(tensors)(nested_detach(t) for t in tensors)\n",
    "        return tensors.detach()\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        mode = inputs[\"mode\"]\n",
    "        text_and_summaries_ids = inputs[\"text_and_summaries_input_ids\"]\n",
    "        text_and_summaries_mask = inputs[\"text_and_summaries_attn_mask\"]\n",
    "        scores = inputs[\"scores\"]\n",
    "\n",
    "        outputs = model(mode, text_and_summaries_ids, text_and_summaries_mask, scores)\n",
    "\n",
    "        loss = outputs[\"loss\"]\n",
    "        output = torch.zeros(2 + 3 * args.n_tasks + 2).float().to(loss.device)\n",
    "        output[0] = loss\n",
    "        output[1] = outputs[\"loss_nce\"]\n",
    "        for j in range(args.n_tasks):\n",
    "            output[2 + j * 3] = outputs[\"accuracy_{}\".format(args.scoring_methods[j])]\n",
    "            output[3 + j * 3] = outputs[\"rank_{}\".format(args.scoring_methods[j])]\n",
    "            output[4 + j * 3] = outputs[\"prediction_{}\".format(args.scoring_methods[j])]\n",
    "        output[-2] = outputs[\"prediction_sum\"]\n",
    "        output[-1] = outputs[\"overall_sum\"]\n",
    "\n",
    "        return (loss, output) if return_outputs else loss\n",
    "\n",
    "    def prediction_step(\n",
    "            self,\n",
    "            model: nn.Module,\n",
    "            inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "            prediction_loss_only: bool,\n",
    "            ignore_keys: Optional[List[str]] = None,\n",
    "    ) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Perform an evaluation step on :obj:`model` using obj:`inputs`.\n",
    "\n",
    "        Subclass and override to inject custom behavior.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`nn.Module`):\n",
    "                The model to evaluate.\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
    "            prediction_loss_only (:obj:`bool`):\n",
    "                Whether or not to return the loss only.\n",
    "            ignore_keys (:obj:`Lst[str]`, `optional`):\n",
    "                A list of keys in the output of your model (if it is a dictionary) that should be ignored when\n",
    "                gathering predictions.\n",
    "\n",
    "        Return:\n",
    "            Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]: A tuple with the loss,\n",
    "            logits and labels (each being optional).\n",
    "        \"\"\"\n",
    "        has_labels = all(inputs.get(k) is not None for k in self.label_names)\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        if ignore_keys is None:\n",
    "            if hasattr(self.model, \"config\"):\n",
    "                ignore_keys = getattr(self.model.config, \"keys_to_ignore_at_inference\", [])\n",
    "            else:\n",
    "                ignore_keys = []\n",
    "\n",
    "        # labels may be popped when computing the loss (label smoothing for instance) so we grab them first.\n",
    "        if has_labels:\n",
    "            labels = nested_detach(tuple(inputs.get(name) for name in self.label_names))\n",
    "            if len(labels) == 1:\n",
    "                labels = labels[0]\n",
    "        else:\n",
    "            labels = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if has_labels:\n",
    "                loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n",
    "                loss = loss.mean().detach()\n",
    "                if isinstance(outputs, dict):\n",
    "                    logits = tuple(v for k, v in outputs.items() if k not in ignore_keys + [\"loss\"])\n",
    "                else:\n",
    "                    logits = outputs[1:]\n",
    "            else:\n",
    "                loss = None\n",
    "                if self.use_amp:\n",
    "                    # with autocast():\n",
    "                    outputs = model(**inputs)\n",
    "                else:\n",
    "                    text_inputs_ids = inputs[\"text_inputs_ids\"]\n",
    "                    text_attention_mask = inputs[\"text_attention_mask\"]\n",
    "                    text_inputs = {\n",
    "                        \"input_ids\": text_inputs_ids,\n",
    "                        \"attention_mask\": text_attention_mask\n",
    "                    }\n",
    "                    outputs = model(**text_inputs)\n",
    "                if isinstance(outputs, dict):\n",
    "                    logits = tuple(v for k, v in outputs.items() if k not in ignore_keys)\n",
    "                else:\n",
    "                    logits = outputs\n",
    "                # TODO: this needs to be fixed and made cleaner later.\n",
    "                if self.args.past_index >= 0:\n",
    "                    self._past = outputs[self.args.past_index - 1]\n",
    "\n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "\n",
    "        logits = nested_detach(logits)\n",
    "        if len(logits) == 1:\n",
    "            logits = logits[0]\n",
    "\n",
    "        return (loss, logits, labels)\n",
    "\n",
    "    def get_train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Returns the training :class:`~torch.utils.data.DataLoader`.\n",
    "\n",
    "        Will use no sampler if :obj:`self.train_dataset` does not implement :obj:`__len__`, a random sampler (adapted\n",
    "        to distributed training if necessary) otherwise.\n",
    "\n",
    "        Subclass and override this method if you want to inject some custom behavior.\n",
    "        \"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "\n",
    "        train_dataset = self.train_dataset\n",
    "        # if is_datasets_available() and isinstance(train_dataset, datasets.Dataset):\n",
    "        #     train_dataset = self._remove_unused_columns(train_dataset, description=\"training\")\n",
    "\n",
    "        return DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "            shuffle=train_dataset.args.shuffle_train,\n",
    "            collate_fn=self.data_collator,\n",
    "            drop_last=self.args.dataloader_drop_last,\n",
    "            num_workers=self.args.dataloader_num_workers,\n",
    "            pin_memory=self.args.dataloader_pin_memory,\n",
    "        )\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    loss_nce = np.mean([preds[i] for i in range(0, len(preds), 1 + 3 * args.n_tasks + 2)])\n",
    "    result = {\n",
    "        \"loss_nce\": loss_nce\n",
    "    }\n",
    "    for j in range(args.n_tasks):\n",
    "        accuracy_arr = [preds[i] for i in range(1 + j * 3, len(preds), 1 + 3 * args.n_tasks + 2)]\n",
    "        accuracy = np.mean(accuracy_arr)\n",
    "        rank_arr = [preds[i] for i in range(2 + j * 3, len(preds), 1 + 3 * args.n_tasks + 2)]\n",
    "        rank = np.mean(rank_arr)\n",
    "        prediction_arr = [preds[i] for i in range(3 + j * 3, len(preds), 1 + 3 * args.n_tasks + 2)]\n",
    "        prediction = np.mean(prediction_arr)\n",
    "        print(\"Task {}, # pred batches: {}\".format(j + 1, len(accuracy_arr)))\n",
    "        result[\"accuracy_{}\".format(args.scoring_methods[j])] = accuracy\n",
    "        result[\"rank_{}\".format(args.scoring_methods[j])] = rank\n",
    "        result[\"prediction_{}\".format(args.scoring_methods[j])] = prediction\n",
    "    prediction_sum = np.mean([preds[i] for i in range(1 + 3 * args.n_tasks, len(preds), 1 + 3 * args.n_tasks + 2)])\n",
    "    result[\"prediction_sum\"] = prediction_sum\n",
    "    overall_sum = np.mean([preds[i] for i in range(1 + 3 * args.n_tasks + 1, len(preds), 1 + 3 * args.n_tasks + 2)])\n",
    "    result[\"overall_sum\"] = overall_sum\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.max_train_size = 1000\n",
    "args.max_val_size=100\n",
    "\n",
    "train_dataset = dataset\n",
    "train_dataset.texts = dataset.texts[:args.max_train_size]\n",
    "train_dataset.summaries = dataset.summaries[:args.max_train_size]\n",
    "train_dataset.labels = dataset.labels[:args.max_train_size]\n",
    "train_dataset.scores = dataset.scores[:args.max_train_size]\n",
    "\n",
    "\n",
    "val_dataset = dataset\n",
    "val_dataset.texts = dataset.texts[args.max_train_size:args.max_train_size+args.max_val_size]\n",
    "val_dataset.summaries = dataset.summaries[args.max_train_size:args.max_train_size+args.max_val_size]\n",
    "val_dataset.labels = dataset.labels[args.max_train_size:args.max_train_size+args.max_val_size]\n",
    "val_dataset.scores = dataset.scores[args.max_train_size:args.max_train_size+args.max_val_size]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 0\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************** Init VAL results:\n",
      "{'eval_runtime': 0.0048, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0}\n",
      "\n",
      "Probability distribution on experts for each task, computed over 0 data points:\n",
      "Task 1 / 2, distribution across experts: ['nan', 'nan', 'nan', 'nan', 'nan', 'nan'], std: nan\n",
      "Task 2 / 2, distribution across experts: ['nan', 'nan', 'nan', 'nan', 'nan', 'nan'], std: nan\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'is_datasets_available' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# training loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     model\u001b[39m.\u001b[39mdisplay_training_labels()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1498\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1500\u001b[0m )\n\u001b[0;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1502\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1503\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1504\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1505\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1506\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1513\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size \u001b[39m=\u001b[39m batch_size\n\u001b[1;32m   1512\u001b[0m \u001b[39m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 1513\u001b[0m train_dataloader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_train_dataloader()\n\u001b[1;32m   1515\u001b[0m \u001b[39m# Setting up training control variables:\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# number of training epochs: num_train_epochs\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39m# number of training steps per epoch: num_update_steps_per_epoch\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[39m# total number of training steps to execute: max_steps\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m total_train_batch_size \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mtrain_batch_size \u001b[39m*\u001b[39m args\u001b[39m.\u001b[39mgradient_accumulation_steps \u001b[39m*\u001b[39m args\u001b[39m.\u001b[39mworld_size\n",
      "\u001b[1;32m/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb Cell 8\u001b[0m in \u001b[0;36mCustomTrainer.get_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrainer: training requires a train_dataset.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=127'>128</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39mif\u001b[39;00m is_datasets_available() \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(train_dataset, datasets\u001b[39m.\u001b[39mDataset):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m     train_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remove_unused_columns(train_dataset, description\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m \u001b[39mreturn\u001b[39;00m DataLoader(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m     train_dataset,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtrain_batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=138'>139</a>\u001b[0m     pin_memory\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdataloader_pin_memory,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/main_vv.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=139'>140</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'is_datasets_available' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "if True:\n",
    "    results = trainer.evaluate()\n",
    "    print(\"*\" * 50, \"Init VAL results:\")\n",
    "    print(results)\n",
    "    model.moe.display_tasks_probs()\n",
    "\n",
    "# training loop\n",
    "if True:\n",
    "    trainer.train()\n",
    "    model.display_training_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
